import argparse
import numpy as np

def get_config():
    parser = argparse.ArgumentParser()
    
    # parser.add_argument('--variables', type=str, default="pr")
    parser.add_argument('--n_visual', type=int, default=8)
    parser.add_argument('--seed', type=int, default=222)
    parser.add_argument('--print_every_nepoch', type=int, default=1)
    parser.add_argument('--sample_every_nepoch', type=int, default=50)
    parser.add_argument('--burn_in', type=int, default=0)
    
    parser.add_argument('--method', type=str, default="eng_unet", choices=['eng', 'eng_lowr', 'eng_unet', 'eng_2step', 'eng_temporal', 'eng_2step_avg-pool', 'DPA', 'linear', 'nn_det', 
                                                                           'crps_pw', "nn_det_per_variable", "crps_pw_per_variable", "residual", "residual_from_mean", "eng_unet_per_variable"])
    parser.add_argument('--conv', action='store_true', help = "whether to use convolutional layers")
    parser.add_argument('--nicolai_layers', action='store_true', help = "whether to use Nicolai layers")
    parser.add_argument('--conv_concat', action='store_true', help = "whether to use convolutional layers but with the concatenating noise architecture")
    parser.add_argument('--num_noise_channels', type=int, default=1, help = "number of noise channels to concatenate")
    parser.add_argument('--mlp_conv', action='store_true', help = "whether to combine MLP and convolutional layers")
    parser.add_argument('--conv_dim', type=int, default=16, help="hyperparameter for the convolutional layers")
    
    # data loading
    parser.add_argument('--variables', type=str, required=False, default = ["pr"], nargs='+')
    parser.add_argument('--variables_lr', type=str, required=False, default = None, nargs='+')
    parser.add_argument('--n_models', type=int, default=1)
    parser.add_argument('--run_indices', required=False, nargs='+', type=int, default = np.arange(0,8), help = "which of the GCM-RCM runs to use (currently on in coarse only)")
    parser.add_argument('--norm_method_input', type=str, default=None)
    parser.add_argument('--norm_method_output', type=str, default=None)
    parser.add_argument('--fft', action='store_true', help="whether to use FFT for the super-resolution")
    parser.add_argument('--coarsened_hr', action='store_true')
    parser.add_argument('--predict_lr', action="store_true")
    parser.add_argument('--kernel_size_lr', type=int, default=1, help="for GCM to low-res data; smooth with average kernel")   
    parser.add_argument('--stride_lr', type=int, default=None, help="average pooling for xc data")
    parser.add_argument('--padding_lr', type=int, default=None, help="average pooling for xc data")   
    parser.add_argument('--kernel_size_hr', type=int, default=1, help="for super-resolution; smooth also the HR target with average kernel to learn intermediate steps")
    parser.add_argument('--mask_gcm', action='store_true', help="mask out the GCM data inside RCM domain (very rough)")
    parser.add_argument('--tr_te_split', type=str, default="random", choices=["random", "gcm", "rcm", "rcm_gcm", "run_indices"], help="whether to split the data randomly into train / test or test extrapolation based on GCMs")
    parser.add_argument('--tr_te_split_ratio', type=float, default=0.9, help="ratio of train data")
    parser.add_argument('--test_model_index', type=int, default=None, help="which GCM to use for TEST data; only if tr_te_split is gcm or rcm")
    parser.add_argument('--train_model_index', type=int, default=None, help="which GCM to use for TRAIN data; only if tr_te_split is gcm or rcm")
    parser.add_argument('--train_run_indices', type=int, nargs='+', default=None, help="which GCM-RCM runs to use for training; only if tr_te_split is run_indices")
    parser.add_argument('--test_run_indices', type=int, nargs='+', default=None, help="which GCM-RCM runs to use for testing; only if tr_te_split is run_indices")
    parser.add_argument('--clip_quantile_data', type=float, default=None, help="in dataloading, clip HR values at the quantile")
    parser.add_argument('--old_data', action='store_true', help="use the old data sources")
    parser.add_argument('--only_winter', action='store_true', help="use only winter months")
    parser.add_argument('--server', default="ada", choices= ["ada", "euler"])
    parser.add_argument('--filter_outliers', action='store_true', help="whether to filter outliers in the data")
    parser.add_argument('--precip_zeros', type=str, default="random")
    
    # method setup    
    parser.add_argument('--batch_size', type=int, default=512)
    parser.add_argument('--hidden_dim', type=int, default=1000)
    parser.add_argument('--hidden_dim_coarse', type=int, default=20)
    parser.add_argument('--layer_shrinkage', type=int, default=16, help = "for StoUnet, shrinking factor of later layers compared to out dim")
    parser.add_argument('--layer_shrinkage_coarse', type=int, default=1, help = "for StoUnet, shrinking factor of later layers compared to out dim")
    parser.add_argument('--noise_dim', type=int, default=100)
    parser.add_argument('--noise_dim_coarse', type=int, default=10)
    parser.add_argument('--dropout', action='store_true')
    parser.add_argument('--noise_std', type=float, default=1)
    parser.add_argument('--out_act', type=str, default=None)
    parser.add_argument('--out_act_coarse', type=str, default=None)
    parser.add_argument('--num_layer', type=int, default=6)
    parser.add_argument('--num_layer_coarse', type=int, default=6)
    parser.add_argument('--preproc_layer', action='store_true')
    parser.add_argument('--preproc_dim', type=int, default=20)
    parser.add_argument('--avg_constraint', action='store_true', help="for pure super-resolution map, add average constraint")
    parser.add_argument('--max_loss', action='store_true', help="for pure super-resolution map, add loss for spatial max")
    parser.add_argument('--norm_loss', action='store_true', help="for pure super-resolution map and for coarse in coarse from super, add loss for statistics across locations and days")
    parser.add_argument('--norm_loss_loc', action='store_true')
    parser.add_argument('--lambda_norm_loss_loc', type=float, default=1, help="in norm loss, scale the loss across locations with this factor")
    parser.add_argument('--norm_loss_batch', action='store_true')
    parser.add_argument('--agg_norm_loss', type=str, default="mean", help="for norm loss batch, how to aggregate over locations")
    parser.add_argument('--norm_loss_per_var', action='store_true', help="for coarse in coarse from super multivariate, add loss for statistics across locations and days, sep for each variable")
    #parser.add_argument('--p_norm_loss', type=float, default=None, help="norm for the norm loss", nargs='+')
    parser.add_argument('--p_norm_loss_loc', type=float, default=None, help="norm for the norm loss", nargs='+')
    parser.add_argument('--p_norm_loss_batch', type=float, default=None, help="norm for the norm loss", nargs='+')
    parser.add_argument('--lambda_coarse', type = float, default=0.5, help="in coarse from super, scale the direct coarse loss with lambda, and the transformed loss with 1-lambda")
    parser.add_argument('--split_coarse_model', action='store_true', help="have individual coarse models for each GCM-RCM combination")
    parser.add_argument('--one_hot_in_super', action='store_true', help="use one-hot encoding for the input in super-resolution")
    parser.add_argument('--add_x_in_super', action='store_true', help="add the GCM input to the super-resolution model")
    parser.add_argument('--ignore_one_hot_gcm', action='store_true', help="ignore the one-hot encoding for the GCM in the coarse model")
    parser.add_argument('--ignore_one_hot_rcm', action='store_true', help="ignore the one-hot encoding for the RCM in the coarse model")
    
    # loc specific layers
    parser.add_argument('--num_neighbors_res', type=int, default=25, help="number of neighbours for the residual layers in the location-specific layers")
    parser.add_argument('--num_neighbors_ups', type=int, default=9, help="number of neighbours for the upsampling layers in the location-specific layers")
    parser.add_argument('--mlp_depth', type=int, default=3, help="depth of the MLP in the location-specific layers")
    parser.add_argument('--noise_dim_mlp', type=int, default=0, help="dimension of the noise in the MLP in the location-specific layers")
    parser.add_argument('--double_linear', action='store_true', help="whether to use double linear layers in the location-specific layers")
    parser.add_argument('--add_intermediate_loss', action='store_true', help="whether to add intermediate loss in the location-specific layers")
    parser.add_argument('--add_mse_loss', action='store_true', help="whether to add MSE loss in the location-specific layers")
    parser.add_argument('--lambda_mse_loss', type=float, default=1.0)
    parser.add_argument('--not_split_residuals', action='store_true', help = "model directly resid(yupsampled), no additive residuals")
    # others
    parser.add_argument('--data_dir', type=str, default="/r/scratch/groups/nm/downscaling/cordex-ALPS-allyear")
    parser.add_argument('--num_epochs', type=int, default=20000)
    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')
    parser.add_argument('--weight_decay', type=float, default=0, help='weight decay in optimisers')
    parser.add_argument('--save_name', type=str, default="")
    parser.add_argument('--save_dir_super', type=str, default=None)
    parser.add_argument('--save_dir_coarse', type=str, default=None)
    parser.add_argument('--save_model_every', type=int, default=100)
    parser.add_argument('--beta', type=float, default=1)
    parser.add_argument('--beta_norm_loss', type=float, default=1)
    parser.add_argument('--patched_loss', action='store_true', help="use patch loss as well; need to specify patch_size")
    parser.add_argument('--patch_size', type=int, default=8, help = "if specified, use random patches of this size in the loss function")
    parser.add_argument('--logit_transform', action='store_true')
    parser.add_argument('--normal_transform', action='store_true')
    parser.add_argument('--clip_quantile', type=float, default=None, help="in loss; only if logit transform is True, clip predictions at the quantile")
    parser.add_argument('--alpha', type=float, default=1, help = "penalty in ridge regression")
    parser.add_argument('--mlp', action='store_false')
    parser.add_argument('--bn', action='store_true')
    parser.add_argument('--resume_epoch', type=int, default=0)
    parser.add_argument('--sqrt_transform_out', action='store_true')
    parser.add_argument('--sqrt_transform_in', action='store_true')
    
    # only for rank-values
    parser.add_argument('--log_odds_transform', action='store_true', help="whether to apply log-odds transform to the ranks")
    parser.add_argument('--sep_mean_std', action='store_true', help="whether to separate mean and std in the loss for the values")
    
    # only for autoencoder
    parser.add_argument('--dist_enc', type=str, default="deterministic")
    parser.add_argument('--dist_dec', type=str, default="stochastic")
    parser.add_argument('--num_layer_enc', type=int, default=None)
    parser.add_argument('--latent_dim', type=int, default=100)
    parser.add_argument('--k_list', type=int, default=None, nargs='+')
    parser.add_argument('--group_variance_pen', action='store_true', help="whether to add group variance penalty to autoencoder loss")
    parser.add_argument('--linear_maptolatent', action='store_true', help="whether to add linear map to latent space")
    parser.add_argument('--lambda_pred_loss', type=float, default=0.5, help="weight for the prediction loss")
    
    args = parser.parse_args()
    if args.norm_method_input == "None":
        args.norm_method_input = None
    if args.norm_method_output == "None":
        args.norm_method_output = None
    return args